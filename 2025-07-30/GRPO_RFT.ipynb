{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### ⚠️ **Warning: Please note that running the GRPO training job in this notebook to completion has an estimated cost of over $300**.\n",
        "\n",
        "GRPO training runs for 1000 steps by default. You can stop your training job early via the UI after you're satisfied with seeing the performance. (For example after 50-100 steps is where you can start to see the model learning the rewards.)"
      ],
      "metadata": {
        "id": "BWHvRcC3XKUG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment Set Up"
      ],
      "metadata": {
        "id": "bbOzfLz7cq6V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First of all get your API keys here (you get $25 Free credits): https://predibase.com/fine-tuning"
      ],
      "metadata": {
        "id": "0uwcjWYvzAHU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cp8v47dHg4e2"
      },
      "outputs": [],
      "source": [
        "! pip install predibase\n",
        "! pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "id": "BpG93vAeUoxO",
        "outputId": "93a0b454-281d-44f3-a80e-0dd2802a49d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.11.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from predibase import *\n",
        "\n",
        "pb = Predibase(api_token = \"{replace_with_token}\")"
      ],
      "metadata": {
        "id": "RjljqN-DhDjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "v0nICMtqcej8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"<|im_start|>system\n",
        "You are a helpful assistant. You first think about the reasoning process step by step and then provide the user with an answer.<|im_end|>\n",
        "<|im_start|>user\n",
        "Using the numbers {nums}, create an equation that equals {target}. You can use basic arithmetic operations (+, -, *, /) and parentheses, and each number can only be used once. Show your work in <think> </think> tags. And return the final equation and answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\n",
        "<|im_start|>assistant\n",
        "Let me solve this step by step.\n",
        "<think>\"\"\""
      ],
      "metadata": {
        "id": "O9MyTb7phOD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_row(row):\n",
        "    return template.format(\n",
        "        nums=row[\"nums\"],\n",
        "        target=row[\"target\"]\n",
        "    )"
      ],
      "metadata": {
        "id": "fkNVhskXaD25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load the dataset\n",
        "dataset = load_dataset(\"predibase/countdown\")\n",
        "train_df = pd.DataFrame(dataset[\"train\"])\n",
        "eval_df = pd.DataFrame(dataset[\"test\"])"
      ],
      "metadata": {
        "id": "UaU7PJHKahGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[\"prompt\"] = train_df.apply(format_row, axis=1)\n",
        "eval_df[\"prompt\"] = eval_df.apply(format_row, axis=1)\n",
        "\n",
        "print(\"train_df\")\n",
        "print(train_df.head(5))\n",
        "print(eval_df.iloc[0][\"prompt\"])\n",
        "print(\"--------\")\n",
        "print(\"eval_df\")\n",
        "print(eval_df.head(5))\n",
        "print(eval_df.iloc[0][\"prompt\"])\n",
        "\n",
        "train_df.to_json(\"./countdown_train.jsonl\", lines=True, orient=\"records\")"
      ],
      "metadata": {
        "id": "WMJ_HUY9auFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reward Functions\n",
        "Reward functions are how the model will determine how well it's doing during training. It's important to understand how they are defined."
      ],
      "metadata": {
        "id": "aE_fA_YNeF7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import regex as re\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "# Check if the output is properly formatted\n",
        "def format_reward_func(prompt: str, completion: str, example: dict[str, str]) -> int:\n",
        "    # Imported packages must be inside each reward function\n",
        "    import re\n",
        "\n",
        "    reward = 0\n",
        "    try:\n",
        "        # Add synthetic <think> as it's already part of the prompt and prefilled\n",
        "        # for the assistant to more easily match the regex\n",
        "        completion = \"<think>\" + completion\n",
        "\n",
        "        # Check if the format matches expected pattern:\n",
        "        # <think> content </think> followed by <answer> content </answer>\n",
        "        regex = (\n",
        "            r\"^<think>\\s*([^<]*(?:<(?!/?think>)[^<]*)*)\\s*<\\/think>\\n\"\n",
        "            r\"<answer>\\s*([\\s\\S]*?)\\s*<\\/answer>$\"\n",
        "        )\n",
        "\n",
        "        # Search for the regex in the completion\n",
        "        match = re.search(regex, completion, re.DOTALL)\n",
        "        if match is not None and len(match.groups()) == 2:\n",
        "            reward = 1.0\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    print(f\"Format reward: {reward}\")\n",
        "    return reward\n",
        "\n",
        "# Check if the output contains the correct answer\n",
        "def equation_reward_func(prompt: str, completion: str, example: dict[str, str]) -> int:\n",
        "    # Imported packages must be inside each reward function\n",
        "    import re\n",
        "    import ast\n",
        "\n",
        "    reward = 0.0\n",
        "    try:\n",
        "        # add synthetic <think> as its already part of the prompt and prefilled\n",
        "        # for the assistant to more easily match the regex\n",
        "        completion = \"<think>\" + completion\n",
        "        match = re.search(r\"<answer>\\s*([\\s\\S]*?)\\s*<\\/answer>\", completion)\n",
        "        if not match:\n",
        "            print(\"No answer found in completion. Equation reward: 0.0\")\n",
        "            return 0.0\n",
        "\n",
        "        # Extract the \"answer\" part from the completion\n",
        "        equation = match.group(1).strip()\n",
        "        # Extract all numbers from the equation\n",
        "        used_numbers = [int(n) for n in re.findall(r'\\d+', equation)]\n",
        "\n",
        "        # Convert the example[\"nums\"] to a list if it's a string\n",
        "        # This is common for columns like lists in datasets\n",
        "        if isinstance(example[\"nums\"], str):\n",
        "            example[\"nums\"] = ast.literal_eval(example[\"nums\"])\n",
        "\n",
        "        # Check if all numbers are used exactly once\n",
        "        if sorted(used_numbers) != sorted(example[\"nums\"]):\n",
        "            print(\"Numbers used in equation not the same as in example. Equation reward: 0.0\")\n",
        "            return 0.0\n",
        "\n",
        "        # Define a regex pattern that only allows numbers, operators, parentheses, and whitespace\n",
        "        allowed_pattern = r'^[\\d+\\-*/().\\s]+$'\n",
        "        if not re.match(allowed_pattern, equation):\n",
        "            print(\"Equation contains invalid characters. Equation reward: 0.0\")\n",
        "            return 0.0\n",
        "\n",
        "        # Evaluate the equation with restricted globals and locals\n",
        "        result = eval(equation, {\"__builtins__\": None}, {})\n",
        "        # Check if the equation is correct and matches the ground truth\n",
        "        if abs(float(result) - float(example[\"target\"])) < 1e-5:\n",
        "            reward = 1.0\n",
        "        else:\n",
        "            print(\"Equation is incorrect. Equation reward: 0.0\")\n",
        "            return 0.0\n",
        "\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    print(f\"Equation reward: {reward}\")\n",
        "    return reward"
      ],
      "metadata": {
        "id": "xwQf0_wPeYzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note the following:\n",
        "- `completions` are the model outputs for a given prompt and `examples` is a list of dicts, with each dict representing a row of the train dataset.\n",
        "- The reward for each completion is appended to the list `rewards`, so the output is a list of floats with the same length as our dataset\n",
        "- While the rewards in this case take on the binary values of 0.0 and 1.0, they can take on any float values."
      ],
      "metadata": {
        "id": "fLHSNWbLfede"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuning"
      ],
      "metadata": {
        "id": "afHssqTsczMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload a dataset\n",
        "try:\n",
        "  dataset = pb.datasets.from_file(\"./countdown_train.jsonl\", name=\"countdown_train\")\n",
        "except:\n",
        "  dataset = pb.datasets.get(\"countdown_train\")"
      ],
      "metadata": {
        "id": "JBnb2QeebS41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new repo/fetch an existing one\n",
        "repo = pb.repos.create(name=\"countdown\", description=\"GRPO Countdown Runs\", exists_ok=True)"
      ],
      "metadata": {
        "id": "AxW66ozBdmHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Launch the finetuning job!\n",
        "adapter = pb.adapters.create(\n",
        "    config=GRPOConfig(\n",
        "        base_model=\"qwen2-5-7b-instruct\",\n",
        "        reward_fns=RewardFunctionsConfig(\n",
        "            functions={\n",
        "              \"format\": RewardFunction.from_callable(format_reward_func),\n",
        "              \"answer\": RewardFunction.from_callable(equation_reward_func),\n",
        "            }\n",
        "        ),\n",
        "        target_modules=[\n",
        "            'q_proj', 'v_proj', 'k_proj', 'o_proj',\n",
        "            'gate_proj', 'up_proj', 'down_proj'\n",
        "        ],\n",
        "    ),\n",
        "    dataset=\"countdown_train\",\n",
        "    repo=repo,\n",
        "    description=\"Countdown!\"\n",
        ")"
      ],
      "metadata": {
        "id": "Nb7fb_PWd8oE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate the Model"
      ],
      "metadata": {
        "id": "b_oXR5u0gO7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pb.deployments.create(\n",
        "    name=\"my-qwen2-5-7b-instruct\",\n",
        "    config=DeploymentConfig(\n",
        "        base_model=\"qwen2-5-7b-instruct\",\n",
        "        cooldown_time=600,\n",
        "        min_replicas=0,\n",
        "        max_replicas=1\n",
        "    ),\n",
        "    description=\"Created with GRPO Countdown notebook\",\n",
        ")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-quP9PtMgSiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adapter_id = \"countdown/1\" # Change the version number as needed (you can find this in the UI)\n",
        "\n",
        "lorax_client = pb.deployments.client(\"my-qwen2-5-7b-instruct\")\n",
        "\n",
        "eval_outputs = []\n",
        "for i, row in eval_df.iterrows():\n",
        "  prompt = row[\"prompt\"]\n",
        "  completion = lorax_client.generate(prompt, adapter_id=adapter_id).generated_text\n",
        "  eval_outputs.append({\"prompt\": prompt, \"completion\": completion})\n",
        "\n",
        "eval_outputs = pd.DataFrame(eval_outputs)\n",
        "print(eval_outputs.head(5))\n",
        "\n",
        "eval_outputs.to_json(\"./eval_outputs.jsonl\", lines=True, orient=\"records\")"
      ],
      "metadata": {
        "id": "bPZD2qiOgzY_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}